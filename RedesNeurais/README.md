<h2 align='center'> üß†Experimentos de redes neurais artificiaisüíª </h2>

<img src="https://user-images.githubusercontent.com/107013536/225460843-633e8f40-683f-4d8f-a420-c627d1d0a459.png" width="100" hight="100">

Redes neurais s√£o algoritmos extremamente importantes para a tecnologia atual. Altamente utilizados em Aprendizado de M√°quina, uma vez que s√£o capazes de identificar padr√µes de comportamentos, permitindo o desenvolvimento desses sistemas de aprendizagem pr√≥pria, dado um conjunto de dados.

Essa pasta reservada para experimentos de redes neurais realizados durante as aulas da disciplina. Nela √© poss√≠vel ver que h√° diferentes arquivos .ipynb os quais dizem respeito ao notebooks do JupyterLab. Ao todo se encontram atualizados dois experimentos completos e um arquivo para armazenar fun√ß√µes.

<hr>

<summary><b> "funcoes.py" </b></summary>
<p align='justify'>
Esse arquivo foi criado com o intuito de armazenar programas de fun√ß√µes globais que podem ser usadas em diferentes notebooks importando-as pelo comando <b>"from funcoes import [nome da funcao]"</b>, de maneira a deixar o c√≥digo principal mais organizado e facilitar a utiliza√ß√£o das fun√ß√µes definidas apenas importando do arquivo quando necess√°rio usar qualquer uma chamando por seu respectivo nome definido.
</p>

<summary><b> "classes.py" </b></summary>
<p align='justify'>
Esse arquivo foi criado com o intuito de armazenar as classes usadas na aula de Redes Neurais, permitindo que a classe seja usada em diferentes notebooks de experimentos sem que ela precise ser escrita dentro dos arquivos toda vez que precisar ser usada. Tudo o que √© preciso para us√°-la √© importar atrav√©s do comando <b>"from classes import [nome da classe]"</b>. Isso permite, tamb√©m que a formata√ß√£o de escrita e organiza√ß√£o do notebook esteja muito mais bonita e clara. 
</p>

<h3> Experimentos de aula </h3>
<p align='justify'>
Essa √© uma lista para descrever os experimentos de redes neurais trabalhados durante as aulas. Para ver as descri√ß√µes, basta clicar no tri√¢ngulo ao lado dos nomes dos experimentos. Caso queria acessar os algoritmos, clique nos hiperlinks em azul de cada um dos experimentos.
</p>

<details><summary><b><a href='https://github.com/Sophlechim/Redes-Neurais---Sophia/blob/main/RedesNeurais/experimento%20R.02%20-%20classes.ipynb'> "experimento R.02 - classes.ipynb" </a></b></summary>
<p align='justify'>
Estamos finalmente fazendo o nosso primeiro expeirmento do segmento de Redes Neurais, o qual nos introduz um novo modelo de c√≥digo classes. Vale ressaltar que este e o terceiro experimento foram feitos antes do R.01, pois n√£o iremos trabalhar com ele, portanto considere que ele n√£o exista.
</p>
<p align='justify'>
Mas o que s√£o classes??? Elas s√£o um modelo de c√≥digo que serve para criar objetos, quaisquer coisas, pois em <b><i>Python</i></b>, quase tudo pode ser classificado como objeto. √â uma forma muito √∫til de organizar dados e fun√ß√µes, de maneira que elas podem ser armazenadas em sec√ß√µes diferentes para cada tipo de objeto que queremos criar. A estrutura que exige o uso das classes √© complexa de uma forma que apenas listas, fun√ß√µes, dicion√°rios e conjuntos n√£o conseguem realizar.
</p>
</details>

<details><summary><b><a href='https://github.com/Sophlechim/Redes-Neurais---Sophia/blob/main/RedesNeurais/experimento%20R.03%20-%20construindo%20um%20grafo%20automaticamente.ipynb'> "experimento R.03 - construindo um grafos automaticamente.ipynb" </a></b></summary>
<p align='justify'>
 Seguindo o assunto sobre classes em <b><i>Python</i></b>, esse experimento tr√™s, feito na mesma aula que o experimento dois, utilizamos da modelo de classes para construir o primeiro passo de uma rede neural artificial usando um grafo que trabalhamos em sala de aula, fora do JupyterLab Notebook. Podemos ver esse grafo constru√≠do na sec√ß√£o <b><u>Refazendo o grafo que fizemos na aula anterior`</u><b>. 
</p>
<p align='justify'>
<b>Nota:</b> Por enquanto, qualquer grafo plotado neste Notebook n√£o pode ser visualizado, pois meu computador n√£o possui o software necess√°rio para retornar a imagem dentro do JupyterLab. Caso n√£o tenha o software em seu computador e queria ver sem precisar baix√°-lo, primeiramente, certifique-se de que tenha instalado o pacote <b><i>graphviz</i></b> (pode baix√°-lo usando o c√≥digo presente na c√©lula 'raw' do notebook). Depois, acesse o seguinte link <a href="https://dreampuf.github.io/GraphvizOnline/"> GraphvizOnline </a> e copie cada um dos URL's retornados pelos c√≥digos acima e substitua o que est√° no script em preto pelo grafo que deseja ver.
</p>
</details>

<details><summary><b><a href='https://github.com/Sophlechim/Redes-Neurais---Sophia/blob/main/RedesNeurais/experimento%20R.04%20-%20computando%20gradientes%20locais.ipynb'> "experimento R.04 - computando gradiente locais.ipynb" </a></b></summary>
<p align='justify'>
Partimos agora para a parte matem√°tica da constru√ß√£o de um grafo computacional para uma rede neural artificial. Essa constru√ß√£o utilizou-se do mesmo conceito de classe trabalhado nos experimentos anteriores, para construir nossos grafos. Sendo assim, continuamos a trabalhar com a nossa classe criada no notebook anterior, R.03, para gerar o grafo computacional, de forma que atualizamos ele com novas informa√ß√µes com o intuito de calcular os gradientes locais atrav√©s do processo chamado <b><i>backpropagation</i></b>. Este processo √© uma base muito importante para a constru√ß√£o de uma rede neural, usando a <b><i>regra de cadeia</i></b> para treinar o modelo de rede, ajustando o peso das liga√ß√µes da rede para minimizar a diferen√ßa entre o vetor de sa√≠da real e o esperado, como dito pelos autores do do artigo <a href='https://www.nature.com/articles/323533a0'>"Learning representation by back-propagation errors"</a>. A qualidade desse ajuste √© medida pelo gradiente local de cada v√©rtice num√©rico.
</p>
<p align='justify'>
Com isso, n√≥s buscamos computar os gradientes locais e treinar uma rede neural manualmente, ou seja, definimos uma equa√ß√£o para calcul√°-los e alteramos par√¢metros de maneira n√£o muito pr√°tica. Por isso, aprendemos tamb√©m √† calcular o gradiente de maneira autom√°tica.
</p>
</details>

<details><summary><b><a href='https://github.com/Sophlechim/Redes-Neurais---Sophia/blob/main/RedesNeurais/experimento%20R.05%20-%20finalizando%20a%20classe%20Valor.ipynb'> "experimento R.05 - finalizando a classe Valor.ipynb" </a></b></summary>
<p align='justify'>
Chegamos agora em um momento final para que nossa classe que trabalhamos nas √∫ltimas aulas possa ser treinada, pois aqui, nesse quinto experimento de redes neurais artificiais, vamos finalizar a classe <b><u>Valor</u></b>, de forma que ela esteja aprimorada da melhor maneira poss√≠vel. Portanto, aqui, o que procuramos √© tornar poss√≠vel que ela possa realizar diferentes tipos de opera√ß√µes que v√£o muito al√©m daquelas j√° existentes, acompanhando o funcionamento na nossa rede neural artificial.
Sendo assim, pudemos observar a forma que as opera√ß√µes se comportavam conforme rodamos cada uma delas antes e depois de definir as fun√ß√µes necess√°rias para que as opera√ß√µes escritas pudessem ser entendidas pelo Python.
</p>
</details>

<details><summary><b><a href='https://github.com/Sophlechim/Redes-Neurais---Sophia/blob/main/RedesNeurais/experimento%20R.06%20-%20redes%20neurais%20artificiais.ipynb'> "experimento R.06 - redes neurais artificiais" </a></b></summary>
<p align='justify'>
 Ap√≥s concluir a classe <b><u>Valor</u></b>, a qual agora j√° faz tudo o que precisaremos para funcionar e sustentar nossa rede neural, o que procuramos agora √© construir a nossa rede neural completa. Para isso, estamos aqui, neste notebook R.06, montando uma rede neural parte por parte, de forma que cada parte criada √© uma classe que armazena informa√ß√µes que se√£o respons√°veis por criar e fazer funcionar os elementos que comp√µem uma rede artificial: o neur√¥nio, a camada e uma rede de multicamadas. Essa constru√ß√£o serve tamb√©m para entendermos como funciona uma rede neural artificial, de maneira pausada e aos poucos.
</p>
</details>

‚ö†Ô∏èStatus do segmento: Em andamento üîÑ
